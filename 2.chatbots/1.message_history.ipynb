{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a0577ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"/Users/vansh/Desktop/langchain/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9f908a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d803f2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x118bba7d0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x118cf34d0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"llama-3.1-8b-instant\", groq_api_key = groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc75ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Vansh, it's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 41, 'total_tokens': 69, 'completion_time': 0.028780215, 'prompt_time': 0.002212753, 'queue_time': 0.051248216, 'total_time': 0.030992968}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--32584619-b81c-4944-b114-e80f1a5a589e-0', usage_metadata={'input_tokens': 41, 'output_tokens': 28, 'total_tokens': 69})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, human\n",
    "model.invoke([HumanMessage(content=\"hi my name is vansh\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74ef3e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm glad you're interested in AI. I'm a large language model, I don't have personal memories like humans do, but I can recall our conversation from the start. You introduced yourself as Vansh, and I'm happy to continue our conversation about AI.\\n\\nSo, what would you like to know about AI? Would you like to know about its history, types (e.g., narrow, general, superintelligence), applications, or something else?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 94, 'prompt_tokens': 92, 'total_tokens': 186, 'completion_time': 0.139258242, 'prompt_time': 0.00605788, 'queue_time': 0.04910944, 'total_time': 0.145316122}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_33e8adf159', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--27fe1988-9493-4c98-950f-093fc2713fa6-0', usage_metadata={'input_tokens': 92, 'output_tokens': 94, 'total_tokens': 186})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content = \"hi my name is vansh\"),\n",
    "        AIMessage(content=\"Hi Vansh, it's nice to meet you. Is there something I can help you with or would you like to chat?\"),\n",
    "        HumanMessage(content=\"i want to know about ai and do u still remember my name?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc456063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d193fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9da3977",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"hi my name is vansh and i m a ai engineer\")],\n",
    "    config = config \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2a34d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Vansh. As an AI engineer, you must be at the forefront of innovation. What specific aspects of AI do you enjoy working with, such as deep learning, machine learning, or perhaps conversational AI?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6534e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Vansh.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 201, 'total_tokens': 209, 'completion_time': 0.009515162, 'prompt_time': 0.011010912, 'queue_time': 0.050482508, 'total_time': 0.020526074}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--0559bc63-5ca9-4f2d-b437-575f5036b6bd-0', usage_metadata={'input_tokens': 201, 'output_tokens': 8, 'total_tokens': 209})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name??\")],\n",
    "    config = config \n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba072b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your name is Vansh, and you're an AI engineer!\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1 = {\"configurable\": {\"session_id\": \"chat1\"}}\n",
    "result = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name??\")],\n",
    "    config= config1\n",
    ")\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34de6051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are expert at greeting\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f04cbc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Vansh, it's nice to meet you. How are you doing today?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 46, 'total_tokens': 65, 'completion_time': 0.01744222, 'prompt_time': 0.002158639, 'queue_time': 0.052786791, 'total_time': 0.019600859}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--da04ce5a-466e-4638-b03e-023ee0b21788-0', usage_metadata={'input_tokens': 46, 'output_tokens': 19, 'total_tokens': 65})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke ({\"messages\":[ HumanMessage(content=\"hi my name is vansh\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f29eb72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d671880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Vansh. I'm glad you said hello. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 46, 'total_tokens': 78, 'completion_time': 0.041473543, 'prompt_time': 0.002087671, 'queue_time': 0.050759089, 'total_time': 0.043561214}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--6a81bfbb-c230-4f33-86e9-432ef078f00c-0', usage_metadata={'input_tokens': 46, 'output_tokens': 32, 'total_tokens': 78})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"100\"}}\n",
    "result = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"hi my name is vansh\")],\n",
    "    config=config\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74f3921e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are a good assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='do u remeber my name', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='it is vansh', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='repeat again', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='vansh', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer = trim_messages(\n",
    "    max_tokens = 30, \n",
    "    strategy = \"last\",\n",
    "    token_counter = model,\n",
    "    include_system = True,\n",
    "    allow_partial = False,\n",
    "    start_on = \"human\"\n",
    "    )\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you are a good assistant\"),\n",
    "    HumanMessage(content=\"hi i m vansh\"),\n",
    "    AIMessage(content=\"hi vansh\"),\n",
    "    HumanMessage(content=\"do u remeber my name\"),\n",
    "    AIMessage(content=\"it is vansh\"),\n",
    "    HumanMessage(content=\"repeat again\"),\n",
    "    AIMessage(content=\"vansh\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87784a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chains = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer)\n",
    "    |prompt | model \n",
    ")\n",
    "\n",
    "response = chains.invoke({\"messages\":messages + [HumanMessage(content= \" what i asked u last?\")]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "755e004e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You asked me to repeat again and also told me that I am an expert at greeting and a good assistant.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 67, 'total_tokens': 90, 'completion_time': 0.035671749, 'prompt_time': 0.00364512, 'queue_time': 0.05271116, 'total_time': 0.039316869}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--2aa265eb-8251-4693-8afe-14cc09e4bee1-0', usage_metadata={'input_tokens': 67, 'output_tokens': 23, 'total_tokens': 90})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33292721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked me to repeat again, and then asked what you had asked me last. You initially asked me to repeat again, which I did, and then you responded with \"vansh\", but I think you were expecting a response to your initial question.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chains, get_session_history, input_messages_key=\"messages\")\n",
    "config = {\"configurable\":{\"session_id\": \"123\"}}\n",
    "result = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what i asked u last?\")]\n",
    "    }, config = config\n",
    ")\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8a1807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
